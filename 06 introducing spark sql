ðŸ“Œ Spark SQL â€“ Databases & Table Creation

ðŸ”¹ By default, Spark SQL creates tables in the default database if no database is specified.

ðŸ”¹ List all available databases:
spark.sql("SHOW DATABASES").show()

ðŸ”¹ Filter databases using SQL LIKE:
spark.sql("SHOW DATABASES LIKE 'test%'").show()

ðŸ”¹ Filter databases using DataFrame filter:
spark.sql("SHOW DATABASES").filter("databaseName LIKE 'test%'").show()

ðŸ”¹ Switch to a specific database:
spark.sql("USE retail")

ðŸ”¹ Show all tables in the current database:
spark.sql("SHOW TABLES").show()

ðŸ”¹ Create a table with just the name (no schema):
spark.sql("CREATE TABLE IF NOT EXISTS employees")

ðŸ”¹ Create an empty table if it does not exist with just table and column names:
spark.sql("CREATE TABLE IF NOT EXISTS employees (id INT, name STRING)")

ðŸ”¹ Create a table only if it does not already exist with full schema and datatypes:
spark.sql("""
    CREATE TABLE IF NOT EXISTS employees (
        id INT,
        name STRING,
        department STRING
    )
""")

ðŸ”¸ Note:
In Python environments (like PySpark, Jupyter), always use triple quotes (""") for multi-line SQL strings. Using a multi-line string with single quotes causes a syntax error.

ðŸ“Œ Spark â€“ Persistence

Persistence means keeping a DataFrame or RDD in memory (or disk) to avoid recomputation in future actions.

Common levels:
- MEMORY_AND_DISK (default)
- MEMORY_ONLY
- DISK_ONLY

Example:
df.persist()       # Caches in memory and disk  
df.cache()         # Same as persist()  
df.unpersist()     # Removes cached data

ðŸ“Œ Spark SQL â€“ Temporary Views

ðŸ”¹ Temporary views are created from DataFrames to run SQL queries.

ðŸ”¹ Create a temp view:
df.createOrReplaceTempView("employees_view")

ðŸ”¹ Query the view:
spark.sql("SELECT * FROM employees_view").show()

ðŸ”¹ Temp views are not persistent. They exist only during the current Spark session and are not stored in the metastore.

ðŸ“Œ Spark SQL â€“ DataFrame from Temp Table

ðŸ”¹ Insert data into a permanent table from a temporary view:
spark.sql("INSERT INTO db_name.table_name SELECT * FROM temp_view_name")

ðŸ”¹ Ensure that the schema of the temp view matches the target table.

ðŸ”¹ Example:
spark.sql("INSERT INTO retail.employees SELECT * FROM employees_view")

ðŸ”¹ You can also create a DataFrame by reading from a SQL table:
df = spark.sql("SELECT * FROM db_name.table_name")

ðŸ“Œ Spark SQL â€“ Describe Table

ðŸ”¹ View schema of a table:
spark.sql("DESCRIBE TABLE employees").show()

Sample output:
+-----------+----------+--------+
| col_name  | data_type| comment|
+-----------+----------+--------+
| id        | int      | null   |
| name      | string   | null   |
| department| string   | null   |
+-----------+----------+--------+

ðŸ”¹ View extended metadata (location, format, etc.):
spark.sql("DESCRIBE TABLE EXTENDED employees").show(truncate=False)

Includes:
- Column definitions
- Detailed table information:
  - Database: default
  - Table: employees
  - Type: MANAGED or EXTERNAL
  - Location: table path
  - Provider: file format
  - Schema: struct<...>

ðŸ“Œ Spark SQL â€“ Show Create Table

ðŸ”¹ View the SQL statement that defines the table:
spark.sql("SHOW CREATE TABLE employees").show(truncate=False)

Sample output:
+------------------------------------------------------------------+
|createtab_stmt                                                   |
+------------------------------------------------------------------+
|CREATE TABLE employees (id INT, name STRING ...) USING parquet ...|
+------------------------------------------------------------------+

ðŸ“Œ Spark SQL â€“ Dropping Managed Tables

ðŸ”¹ Dropping a managed table deletes both its metadata (from metastore) and its data (from storage).

ðŸ”¹ Example:
spark.sql("DROP TABLE IF EXISTS employees")

ðŸ”¹ Managed tables are fully controlled by Spark, including where the data is stored.

ðŸ“Œ Spark SQL â€“ External Tables

ðŸ”¹ External tables only store metadata in the metastore. The data itself remains in the specified path.

ðŸ”¹ Dropping an external table removes only the metadata. The data remains untouched in its location.

ðŸ”¹ Example:
spark.sql("""
    CREATE TABLE IF NOT EXISTS ext_employees (
        id INT,
        name STRING
    )
    USING PARQUET
    OPTIONS (path "/mnt/external/employees")
""")

ðŸ“Œ Spark SQL â€“ Check if Table is Managed or External

ðŸ”¹ Use DESCRIBE EXTENDED to find the table type:
spark.sql("DESCRIBE EXTENDED table_name").show(truncate=False)

ðŸ”¹ Look for the value of "Type" in the output:
- MANAGED means it is a managed table
- EXTERNAL means it is an external table
